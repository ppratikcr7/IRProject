{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/student/Documents/Kaggle/train.csv'\n",
    "test_path = '/home/student/Documents/Kaggle/test.csv'\n",
    "embed_path = '/home/student/Documents/Kaggle/Embeddings/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50\n",
    "max_features  = 20000\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = pd.read_csv(train_path)\n",
    "Test_Data = pd.read_csv(test_path)\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = Train_Data[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentence_train = Train_Data.comment_text\n",
    "list_sentence_test = Test_Data.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list_sentence_train)\n",
    "\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentence_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentence_test)\n",
    "\n",
    "X_train = pad_sequences(list_tokenized_train,maxlen=maxlen)\n",
    "X_trest = pad_sequences(list_tokenized_test,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embedding_index = dict(get_coefs(*o.strip().split()) for o in open(embed_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeds = np.stack(embedding_index.values())\n",
    "emb_mean,emb_std = all_embeds.mean(),all_embeds.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = len(word_index)\n",
    "\n",
    "embedding_matrix = np.random.normal(emb_mean,emb_std,(nb_words,embed_size))\n",
    "\n",
    "for word,i in word_index.items():\n",
    "    if i>=max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210337"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.65890277,  0.23410571,  0.82085032, ...,  0.12365394,\n",
       "          0.28637895,  0.86281029],\n",
       "        [ 0.41800001,  0.24968   , -0.41242   , ..., -0.18411   ,\n",
       "         -0.11514   , -0.78580999],\n",
       "        [ 0.68046999, -0.039263  ,  0.30186   , ..., -0.073297  ,\n",
       "         -0.064699  , -0.26043999],\n",
       "        ...,\n",
       "        [ 0.48654174,  1.14485043,  0.54501572, ...,  0.04782041,\n",
       "         -0.75511799,  0.84744533],\n",
       "        [-0.21611203, -0.28589162,  0.62905614, ..., -0.78789508,\n",
       "         -0.24259589,  0.28527396],\n",
       "        [ 0.62834479,  0.70891561,  0.80176995, ..., -0.49718219,\n",
       "         -0.79705197,  0.61482074]])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[embedding_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(len(tokenizer.word_index),embed_size,weights=[embedding_matrix],trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(60,return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp,outputs=x)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 50)           10516850  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 120)          53280     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 10,576,486\n",
      "Trainable params: 59,636\n",
      "Non-trainable params: 10,516,850\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/4\n",
      "143613/143613 [==============================] - 427s 3ms/step - loss: 0.0690 - acc: 0.9767 - val_loss: 0.0570 - val_acc: 0.9797\n",
      "Epoch 2/4\n",
      "143613/143613 [==============================] - 430s 3ms/step - loss: 0.0549 - acc: 0.9804 - val_loss: 0.0546 - val_acc: 0.9807\n",
      "Epoch 3/4\n",
      "143613/143613 [==============================] - 427s 3ms/step - loss: 0.0514 - acc: 0.9814 - val_loss: 0.0507 - val_acc: 0.9818\n",
      "Epoch 4/4\n",
      "143613/143613 [==============================] - 427s 3ms/step - loss: 0.0489 - acc: 0.9820 - val_loss: 0.0519 - val_acc: 0.9818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f579f526ba8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y,batch_size=32,epochs=4,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 73s 480us/step\n"
     ]
    }
   ],
   "source": [
    "Y_Test = model.predict([X_trest],batch_size=1024,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8047763e-01, 1.2285337e-01, 8.9042568e-01, 2.8640604e-02,\n",
       "        6.4341807e-01, 1.2380260e-01],\n",
       "       [1.2310317e-03, 2.9519044e-06, 1.8308930e-04, 4.1909943e-06,\n",
       "        1.1948345e-04, 2.4531590e-05],\n",
       "       [3.1549134e-03, 2.9887073e-05, 6.2242948e-04, 5.3438915e-05,\n",
       "        3.4563753e-04, 9.7032280e-05],\n",
       "       ...,\n",
       "       [4.6909880e-04, 2.4511138e-07, 3.0577896e-05, 7.9866055e-07,\n",
       "        1.8276907e-05, 8.3774739e-06],\n",
       "       [1.2935498e-03, 1.3585394e-06, 4.4940247e-05, 1.2488029e-05,\n",
       "        2.6538915e-05, 1.5650246e-04],\n",
       "       [9.6579659e-01, 3.0812507e-02, 8.1698942e-01, 8.1266882e-03,\n",
       "        5.2297348e-01, 6.4403112e-03]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': Test_Data.id})\n",
    "count = 0\n",
    "for class_name in list_classes:\n",
    "    submission[class_name] = Y_Test[:,count]\n",
    "    count+=1\n",
    "    \n",
    "submission.to_csv('/home/student/Documents/Kaggle/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
